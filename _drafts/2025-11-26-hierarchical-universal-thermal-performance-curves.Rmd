---
title: "Hierarchical Universal Thermal Performance Curves"
date: 2025-11-26
categories: [statistics]
tags: [statistics, Bayes, hierarchical models, brms, non-linear]
output:
  md_document:
    variant: markdown
    preserve_yaml: true
math: true
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(fig.path = '../assets/img/2025-11-16-hierarchical-universal-thermal-performance-curves/', fig.width = 6, fig.height = 4)
```

# Hierarchical Universal Thermal Performance Curves

## Introduction

A while back (around May 2025) I got interested in thermal performance curves after seeing several interesting presentations at a SEEC symposium by students of Prof. Susana Clusella-Trullas's. One student had fit a plethora of models, both convenetional and otherwise, and found it difficult to decide which was "best". Much reference was made to a paper claiming that there was no "one size fits all" model for this sort of data (<https://www.nature.com/articles/s41467-024-53046-2>).

### Background

A bit of background: thermal performance curves (TPCs) are descriptions of how well organisms perform under a range of temperatures. This is usually assessed experimentally (though in some cases one could use observational data). Performance is a relatively vague concept, but it is intended to serve as an indicator of fitness potential. As such, it can be measured in a number of ways, many of which are particular to the organism under study, and most of which are some kind of rate. In plants, one might measure growth or photosynthetic rate; in bacteria, one might measure colony growth; in animals, movement speed and metabolic rate are frequently used.

It occurred to me that many TPC experiments produce data with a hierarchical structure. For example, in many cases the same individual is measured across the full range of assay temperatures. In other instances, one might have several blocks representing each temperature treatment, with a number of individuals measured in each. Such structure should be taken into account when modelling. To my surprise, however, according to my (admittedly somewhat shallow) research, this did not appear to be the norm. Instead, when multiple measurements are taken per individual the standard approach appears to be to fit a separate model to each individual and discard individuals with "too few data points" or for which the model fails to converge. And when individuals are only measured once but multiple individuals are measured per treatment, their performance values are often averaged as a way of accounting for uneven sampling effort.

Many mathematical models have been proposed to describe the types of TPCs typically encountered. Most of them follow the same basic form: at low temperatures, performance is poor; then, it ramps up exponentially, plateauing just before reaching a peak; finally performance takes a nose-dive, steeply dropping before reaching zero at the critical upper thermal limit. In the paper I mentioned above, Kontopoulos et al. fit 83 of these models to each of 2,739 TPC data sets and found that none of the models consistently outperformed the others. Many if not most of these models are implemented in the comprehensive and widely used R package `rTPC` (<https://padpadpadpad.github.io/rTPC/reference/index.html>), whose documentation includes a number of vignettes on using the `rTPC` functions alongside the `nls.multstart` package for model fitting by maximum likelihood. One thing that's missing is mention of how to explicitly account for the hierarchical nature of many TPC data sets. Instead, recommendations for such data include, for example, i) fitting TPCs independently to each individual when the same individual is measured across the full range of assay temperatures ([here](https://padpadpadpad.github.io/rTPC/articles/fit_many_curves.html)); ii) using the mean for each temperature but using inverse standard deviation weighting to account for measurement error (<https://padpadpadpad.github.io/rTPC/articles/model_weighting.html>); and iii) complicated bootstrapping methods to approximate uncertainty intervals (<https://padpadpadpad.github.io/rTPC/articles/weighted_bootstrapping.html>).

I strongly suspected that a Bayesian hierarchical approach could do all of these things much more elegantly. To test this idea, I tried to replicate some of the examples presented in the `rTPC` vignettes in a Bayesian framework, and then adapt them to the hierarchical way of doing things. I used the brilliant `brms` R package for all my model specification, fitting (using Stan), and post-processing needs. This package makes all of these things easy, and its straightforward syntax for non-linear formulae and prior specifications came in particularly clutch.

```{r Introduction}
set.seed(42)
library(rTPC)
library(tidyverse)
library(ggrepel)
theme_set(theme_bw())

# Prepare for Stan and brms 
library(brms)
options(brms.backend = "cmdstanr")
library(marginaleffects) # for convenient predictions
library(ggdist)
library(tidybayes)
```

## The data

The `chlorella_tpc` data are heavily referenced in the `rTPC` docs and conveniently have a clear hierarchical structure, with multiple temperature assays per algal colony. This is a dataset of 60 TPCs of respiration and photosynthesis of the aquatic algae, Chlorella vulgaris. The colonies were grown at different temperatures for two lengths of time (\~10 generations = "acclimation", \~100 generations = "adaptation")

## Measurement error method

I'll start by reimplementing the weighted samples approach presented [here](https://padpadpadpad.github.io/rTPC/articles/model_weighting.html). `brms` allows us to do this with `resp_se`. I'll also switch to the Pawar et al. (2018) model, as the model in the vignette has three parameters with no biological meaning, which complicates prior specification. The pawar_2018 model has five parameters: $t_{ref}$ is an "anchor" parameter that is fixed, being the temperature at which the $r_{tref}$ rate is estimated. $t_{ref}$ should be below $t_{opt}$, the temperature at which the rate peaks. That rate is informed by the activation energy $e$ and the deactivation energy $eh$, which control the rate of incline and decline. $e$ cannot be greater than $eh$. The `rTPC::get_start_vals()` function is a convenient way to get an idea of plausible values for these parameters.

Here is the model equation:

$$
\mathrm{rate} = \frac{r_{\mathrm{tref}}\; \exp\!\Bigl(\!-\frac{e}{k}\bigl(\frac{1}{T + 273.15} - \frac{1}{T_{\mathrm{ref}} + 273.15}\bigr)\Bigr)}
{1 + \bigl(\frac{e}{e_h - e}\bigr)\; \exp\!\Bigl(\frac{e_h}{k}\bigl(\frac{1}{T_{\mathrm{opt}} + 273.15} - \frac{1}{T + 273.15}\bigr)\Bigr)}
$$

### First, let's fit the ML model.

```{r ML-model}
## get curve data
data("chlorella_tpc")

d_ave <- filter(
  chlorella_tpc,
  process == 'adaptation',
  growth_temp == 33,
  # our rate will be the metabolic rate of photosynthesis
  flux == 'photosynthesis'
) %>%
  group_by(temp) %>%
  # Get the average, SD, and SE
  summarise(
    .,
    sd = sd(rate),
    ave_rate = mean(rate),
    n = n(),
    se = sd / sqrt(n)
  ) %>%
  ungroup()

# plot
ggplot() +
  geom_linerange(aes(x = temp, ymin = ave_rate - sd, ymax = ave_rate + sd), d_ave) +
  geom_point(aes(temp, ave_rate), d_ave, size = 2, shape = 21, fill = 'green4') +
  theme_bw(base_size = 12) +
  theme(legend.position = 'none',
        strip.text = element_text(hjust = 0),
        strip.background = element_blank()) +
  labs(x ='Temperature (ºC)',
       y = 'Metabolic rate',
       title = 'Photosynthesis rates across temperatures') +
  geom_hline(aes(yintercept = 0), linetype = 2)

# Fit with nls.multstart
ml_model_weighted <- nls.multstart::nls_multstart(
  ave_rate ~ pawar_2018(temp = temp, rtref, e, eh, topt, tref = 20),
  data = d_ave,
  iter = c(4, 4, 4, 4),
  start_lower = get_start_vals(
    d_ave$temp,
    d_ave$ave_rate,
    model_name = 'pawar_2018'
  ) -
    10,
  start_upper = get_start_vals(
    d_ave$temp,
    d_ave$ave_rate,
    model_name = 'pawar_2018'
  ) +
    10,
  lower = get_lower_lims(d_ave$temp, d_ave$ave_rate, model_name = 'pawar_2018'),
  upper = get_upper_lims(d_ave$temp, d_ave$ave_rate, model_name = 'pawar_2018'),
  supp_errors = 'Y',
  convergence_count = FALSE,
  # include weights here!
  modelweights = 1 / sd
)
summary(ml_model_weighted)

```

### Fit the Bayesian version.

We need to do some preparation first in order to export the `pawar_2018()` funtion to `brms`.

```{r bayesian-model}

pawar_2018a <- function(temp, r_tref, e, eh, topt) {
  Z <- 273.15 # Absolute zero
  tref <- 20
  tref <- Z + tref
  k <- 8.617e-05 # The boltzmann constant
  boltzmann.term <- r_tref * exp(e / k * (1 / tref - 1 / (temp + Z)))
  inactivation.term <- 1 /
    (1 + (e / (eh - e)) * exp(eh / k * (1 / (topt + Z) - 1 / (temp + Z))))
  return(boltzmann.term * inactivation.term)
}

# Translated to stan
stan_pawar_2018a <- "
  real pawar_2018a(real temp, real rtref, real e, real eh, real topt) {
    real tref = 20;
    real k = 8.617e-5;
    real tref_K = 273.15 + tref;
    real temp_K = 273.15 + temp;
    real topt_K = 273.15 + topt;

    real boltzmann_term = rtref * exp(e / k * ((1 / tref_K) - (1 / temp_K)));
    real inactivation_term = 1 / (1 + (e / (eh - e)) * exp(eh / k * ((1 / topt_K) - (1 / temp_K))));

    return boltzmann_term * inactivation_term;
  }
"

# We also need to constrain e < eh
# See https://www.r-bloggers.com/2023/06/order-constraints-in-bayes-models-with-brms/
stanvars_pawar_2018a <- stanvar(
  scode = stan_pawar_2018a, 
  block = "functions"
) + stanvar(
  scode ='
  if (!(b_e[1] < b_eh[1])) {
    reject("Rejecting proposal as e > eh is a-priori impossible.");
  }
  ',
  block = "tparameters"
)

# Specify the formula
# We now use the se, not the sd
bform_se <- bf(
  ave_rate | se(se,sigma=TRUE)  ~  pawar_2018a(temp, rtref, e, eh, topt),
  rtref ~ 1 ,
  e ~ 1,
  eh ~ 1 ,
  topt ~ 1 ,
  nl = TRUE
)

# Priors
## Make sure to specify tref below the likely peak!
## If it's at or above, it will be overestimated! (Though the model will still fit fine)
## With this data set, I went as high as 37 and got unbiased estimates, but they
## became slightly positively biased at 40, and severely positively biased at 45
## Pawar et al. (2018) explains why this happens. It might be a bigger problem
## for the Sharpe-Schoolfield model, which is the subject of that paper. Unsure.
## But it can go really low (I tested 1 degree C and it worked fine)
priors <- c(
  # Half-normal
  prior(normal(0,0.1), lb = 0, nlpar = "rtref"),
  # Half-student (low) for e
  prior(student_t(3,0.5,0.5), lb = 0, nlpar = "e"),
  # Half-student (high) for eh
  prior(student_t(5,5,2), lb = 0, nlpar = "eh"),
  # Informative prior with reasonable bounds to prevent odd behaviour
  prior(normal(40, 3), lb=30, ub=40, nlpar = "topt"),
  # Sigma
  prior(std_normal(),class="sigma")
)

# Keep the same priors
bayesian_model_weighted <- brm(
  bform_se,
  family = brmsfamily("gaussian"),
  data = d_ave,
  stanvars = stanvars_pawar_2018a,
  prior = priors,
  control = list(adapt_delta = 0.999, max_treedepth = 15),
  cores = 4,
  iter = 4000,
  warmup = 3000,
  refresh = 1000,
  backend = "cmdstanr",
  file = ".brms/pawar-weighted"
)
summary(bayesian_model_weighted)

```

### Let's compare the models

```{r model-compare}
nd <- data.frame(
  temp=seq(15,50,by=0.1)
)

nd %>%
  predictions(
    ml_model_weighted,
    newdata = .,
    type = "fitted"
  ) %>%
  select(temp, estimate, conf.low, conf.high) %>%
  mutate(model = "ml_model_weighted") %>%
  bind_rows(
    bind_cols(
      nd,
      fitted(
        bayesian_model_weighted,
        # se column needs to be in the model, but is ignored when getting fitted values
        # (changing it does not affect the plots)
        newdata = nd %>% mutate(se = mean(d_ave$se)),
        allow_new_levels = TRUE
      )
    ) %>%
      as.data.frame() %>%
      select(temp, estimate = Estimate, conf.low = Q2.5, conf.high = Q97.5) %>%
      mutate(model = "bayesian_model_weighted")
  ) %>%
  as_tibble() %>%
  ggplot(aes(x = temp, y = estimate)) +
  theme_bw(base_size = 12) +
  theme(legend.position = 'none',
        strip.text = element_text(hjust = 0),
        strip.background = element_blank()) +
  labs(x ='Temperature (ºC)',
       y = 'Metabolic rate',
       title = 'Bayesian vs ML SE-weighted model expectations') +
  geom_hline(aes(yintercept = 0), linetype = 2) +
  # add the observed data
  geom_line(
    aes(y = rate, group = curve_id),
    data = filter(
      chlorella_tpc,
      process == 'adaptation',
      growth_temp == 33,
      flux == 'photosynthesis'
    ) %>%
      mutate(curve_id = as.factor(curve_id)) %>%
      as_tibble()
  ) +
  geom_pointrange(
    aes(y = ave_rate, ymax = ave_rate + sd, ymin = ave_rate - sd),
    shape = 21, fill = 'green4',
    data = d_ave
  ) +
  geom_line(aes(colour = model),show.legend = F) +
  geom_ribbon(
    aes(fill = model, ymin = conf.low, ymax = conf.high),
    alpha = 0.2,
    show.legend = F
  ) +
  facet_wrap(~model, nrow = 1)

# We can also look at the posterior draws to see where the Bayesian model's uncertainty comes from

nd %>% 
  mutate(se=1) %>% # ignored
  add_linpred_draws(bayesian_model_weighted,ndraws=1000) %>%
  ggplot(aes(x=temp,y=.linpred))+
  geom_line(aes(group=.draw),alpha=.01)

```

## Hierarchical method

Now, it turns out that fitting the Pawar (2018) model to this data in a fully hierarchical manner is quite difficult, but there is a neat alternative which I'll describe later. But for now, let's give it a go.

```{r pawar-hier-1}
# Don't do any averaging!
d_hier <- filter(
  chlorella_tpc,
  process == 'adaptation',
  growth_temp == 33,
  flux == 'photosynthesis'
) %>%
  mutate(curve_id = as.factor(curve_id)) %>%
  as_tibble()
d_hier

# Start with just random effects on t_opt
bform_hier_topt <- bf(
  rate ~  pawar_2018a(temp, rtref, e, eh, topt),
  rtref ~ 1 ,
  e ~ 1,
  eh ~ 1 ,
  topt ~ 1 + (1 | curve_id), # <---- Note the familiar syntax used here :)
  nl = TRUE
)

# Update the priors
priors_hier <- c(
  priors,
  # half-normal with low sd -- close to zero
  prior(normal(0,0.3),lb=0,class="sd",nlpar="topt")
)

bayesian_model_hier_topt <- brm(
  bform_hier_topt,
  family = brmsfamily("gaussian"),
  data = d_hier,
  stanvars = stanvars_pawar_2018a,
  prior = priors_hier,
  control = list(adapt_delta = 0.999, max_treedepth = 15),
  cores = 4,
  iter = 4000,
  warmup = 3000,
  refresh = 1000,
  backend = "cmdstanr",
  file = ".brms/pawar-h1"
)
summary(bayesian_model_hier_topt)

# Add a random effect on eh? (deactivation energy might vary among individuals)
bform_hier_topt_eh <- bf(
  rate ~  pawar_2018a(temp, rtref, e, eh, topt),
  rtref ~ 1 ,
  e ~ 1,
  eh ~ 1 + (1 | curve_id),
  topt ~ 1 + (1 | curve_id),
  nl = TRUE
)

# Update the priors
priors_hier <- c(
  priors,
  # half-normal with low sd -- close to zero
  prior(normal(0,0.3),lb=0,class="sd",nlpar="topt"),
  prior(normal(0,0.3),lb=0,class="sd",nlpar="eh")
)

bayesian_model_hier_topt_eh <- brm(
  bform_hier_topt_eh,
  family = brmsfamily("gaussian"),
  data = d_hier,
  stanvars = stanvars_pawar_2018a,
  prior = priors_hier,
  control = list(adapt_delta = 0.999, max_treedepth = 15),
  cores = 4,
  iter = 4000,
  warmup = 3000,
  refresh = 1000,
  backend = "cmdstanr",
  file = ".brms/pawar-h2"
)
summary(bayesian_model_hier_topt_eh)


nd %>% 
  add_linpred_draws(bayesian_model_hier_topt_eh,ndraws=1000,re_formula = NA) %>%
  ggplot(aes(x=temp,y=.linpred))+
  geom_line(aes(group=.draw),alpha=.01)+
  # add the observed data
  geom_line(
    aes(y = rate, group = curve_id),
    data = filter(
      chlorella_tpc,
      process == 'adaptation',
      growth_temp == 33,
      flux == 'photosynthesis'
    ) %>%
      mutate(curve_id = as.factor(curve_id)) %>%
      as_tibble()
  ) +
  geom_pointrange(
    aes(y = ave_rate, ymax = ave_rate + sd, ymin = ave_rate - sd),
    shape = 21, fill = 'green4',
    data = d_ave
  )


```

Allowing $t_{opt}$ to vary among individuals worked fine, but for $eh$... eh. Not so good. This is probably overkil, as we only have 3 colonies! But what if we wanted to test whether the curves differed between colonies grown at different temperatures? Now we can use the full power of this approach.

## Getting really fancy: The one TPC to rule them all!

Before doing so, I'll switch over to using a different model which is hot off the press and quite spectacular. It's billed as a "universal thermal performance curve" by the [Arnoldi et al. (2025)](https://doi.org/10.1073/pnas.2513099122) and has a remarkably simple formulation, with three parameters representing the optimal temperature $T_{opt}$, the rate at that optimum $y_{opt}$, and the difference between $T_{opt}$ and the critical upper limit $Delta$. Temperature is in Celcius (I know, crazy!).

$$
\mathrm{rate} = y_{\mathrm{opt}}\times
\exp\!\left(\frac{T - T_{\mathrm{opt}}}{\Delta}\right)\times
\left(1 - \frac{T - T_{\mathrm{opt}}}{\Delta}\right)
$$

### Fit the universal TPC

The simplicity of the formula means we can write much more concise code.

```{r utpc-1}
# Model -------------------------------------------------------------------

# See https://github.com/AndrewLJackson/UTPC-paper/blob/main/import-fit-merge.Rmd#L132C9-L132C68

# performance ~ (yopt * exp( (ta - Topt)/Delta ) * (1 - (ta - Topt)/Delta))
# ta = temp in Celcius!

bform <- bf(
  rate ~ yopt * exp((temp - Topt) / Delta) * (1 - (temp - Topt) / Delta),
  yopt ~ 1 + (1 | curve_id),
  Topt ~ 1 + (1 | curve_id),
  Delta ~ 1 + (1 | curve_id),
  nl = TRUE
)

priors <- c(
  prior(normal(2, 0.25), lb = 0, nlpar = "yopt"),
  prior(normal(1, 3), lb = 0, ub = 20, nlpar = "Delta"),
  prior(normal(40, 3), lb = 30, ub = 50, nlpar = "Topt"),
  prior(normal(0, 0.3), lb = 0, class = "sd", nlpar = "yopt"),
  prior(std_normal(), lb = 0, class = "sd", nlpar = "Topt"),
  prior(normal(0, 0.3), lb = 0, class = "sd", nlpar = "Delta"),
  prior(normal(0, 0.1), lb = 0, class = "sigma")
)

m_UTPC <- brm(
  bform,
  family = brmsfamily("gaussian"),
  data = d_hier,
  prior = priors,
  control = list(adapt_delta = 0.99, max_treedepth = 12),
  cores = 4,
  iter = 2000,
  warmup = 1500,
  refresh = 500,
  backend = "cmdstanr",
  file = ".brms/utpc-1"
)
m_UTPC

plot(
  conditional_effects(m_UTPC, effects = "temp", spaghetti = T, ndraws = 500),
  points = T
)

nd %>% 
  add_linpred_draws(m_UTPC,ndraws=1000,re_formula = NA) %>%
  ggplot(aes(x=temp,y=.linpred))+
  geom_line(aes(group=.draw),alpha=.01)+
  # add the observed data
  geom_line(
    aes(y = rate, group = curve_id),
    data = d_hier
  ) +
  geom_pointrange(
    aes(y = ave_rate, ymax = ave_rate + sd, ymin = ave_rate - sd),
    shape = 21, fill = 'green4',
    data = d_ave
  ) +
  coord_cartesian(ylim=c(0,3))

pp_check(m_UTPC, ndraws = 100)

# Compare to the pawar model that converged
loo(bayesian_model_hier_topt,m_UTPC)

```

The model has no problem fitting random effects on every parameter, despite only having three replicates. Notice also that the model is not constrained to rates above 0 beyond $T_{opt}$. This is because it assumes a function that crosses zero at the critical temperature, i.e., we expect anything beyond that point to be dead...

### Test some hypotheses!

Heartened by how easily the UTPC model fit, we could try testing some biological hypotheses. Arnoldi et al. suggested that, under a warming scenario, the upper thermal limit is a much "harder" trait for natural selection to act on compared to the thermal optimum. As such, we would expect our algae grown at higher temperatures to have higher $T_{opt}$ and lower $Delta$, i.e., a steeper drop-off and a narrower range of good performance.

Let's test that prediction by allowing our parameters to vary by growth temperature. We also estimate separate random effect SDs for each growth temperature.

```{r utpc-by-temp}
d_hier_3temp <- filter(
  chlorella_tpc,
  process == 'adaptation',
  growth_temp %in% c(27, 30, 33),
  flux == 'photosynthesis'
) %>%
  mutate(
    curve_id = as.factor(curve_id),
    growth_temp_fct = as.factor(growth_temp)
  )

bform_UTPC_3temp <- bf(
  rate ~ yopt * exp((temp - Topt) / Delta) * (1 - (temp - Topt) / Delta),
  yopt ~ 0 + (1 | gr(curve_id,by=growth_temp_fct)) + growth_temp_fct,
  Topt ~ 0 + (1 | gr(curve_id,by=growth_temp_fct)) + growth_temp_fct,
  Delta ~ 0 + (1 | gr(curve_id,by=growth_temp_fct)) + growth_temp_fct,
  nl = TRUE
)

m_UTPC_3temp <- brm(
  bform_UTPC_3temp,
  family = brmsfamily("gaussian"),
  data = d_hier_3temp,
  prior = priors,
  # sample_prior = "only",
  control = list(adapt_delta = 0.99, max_treedepth = 12),
  cores = 4,
  iter = 2000,
  warmup = 1500,
  refresh = 500,
  backend = "cmdstanr",
  file = ".brms/utpc-2",
  seed = 1234
)
m_UTPC_3temp
```

#### Reparameterise as log-normal

This model sometimes has trouble sampling, depending on the random seed, so I tried reformulating it in logarithmic form. The formula then becomes:

$$
log\mathrm{(rate)} = log(y_{\mathrm{opt}}) +
\left(\frac{T - T_{\mathrm{opt}}}{\Delta}\right) +
log\left(1 - \frac{T - T_{\mathrm{opt}}}{\Delta}\right)
$$ 

And we just need to change the family to lognormal. Everything else remains unchanged, even the priors!

```{r utpc-lognormal}
bform_UTPC_3temp_lognormal <- bf(
  rate ~ log(yopt) + ((temp - Topt) / Delta) + log(1 - (temp - Topt) / Delta),
  yopt ~ 0 + (1 | gr(curve_id,by=growth_temp_fct)) + growth_temp_fct,
  Topt ~ 0 + (1 | gr(curve_id,by=growth_temp_fct)) + growth_temp_fct,
  Delta ~ 0 + (1 | gr(curve_id,by=growth_temp_fct)) + growth_temp_fct,
  nl = TRUE
)

m_UTPC_3temp_lognormal <- brm(
  bform_UTPC_3temp_lognormal,
  family = brmsfamily("lognormal"),
  data = d_hier_3temp,
  prior = priors,
  control = list(adapt_delta = 0.99, max_treedepth = 12),
  cores = 4,
  iter = 2000,
  warmup = 1500,
  refresh = 500,
  backend = "cmdstanr",
  file = ".brms/utpc-2-log",
  seed = 123
)
m_UTPC_3temp_lognormal
```

I think this works because working in log space is more numerically stable, but I'm not really sure. Anyway, it works!

Was our prediction correct?

```{r}

yopt_plot <- plot_predictions(
  m_UTPC_3temp_lognormal,
  condition = c("growth_temp_fct"),
  nlpar="yopt",
  points = .5,
  re_formula = NA
)+labs(y="yopt",title="yopt",x="Growth temperature")
Topt_plot <- plot_predictions(
  m_UTPC_3temp_lognormal,
  condition = c("growth_temp_fct"),
  nlpar="Topt",
  points = .5,
  re_formula = NA
)+labs(y="Topt",title="Topt",x="Growth temperature")
Delta_plot <- plot_predictions(
  m_UTPC_3temp_lognormal,
  condition = c("growth_temp_fct"),
  nlpar="Delta",
  points = .5,
  re_formula = NA
)+labs(y="Delta",title="Delta",x="Growth temperature")

patchwork::wrap_plots(yopt_plot,Topt_plot,Delta_plot,axes = "collect")

```

Remarkably, the prediction seems to be right. The colonies grown at 33 degrees for \~ 100 generations had a higher thermal optimum (by around 0.7 ${^\circ}C$) but lower $Delta$ (by around 0.9 ${^\circ}C$) than those grown at lower temperatures, implying that the upper thermal limit didn't change, or may have even declined...

Finally, let's look at some predictions.

```{r}
plot_predictions(
  m_UTPC_3temp_lognormal,
  condition = c("temp", "growth_temp_fct"),
  points = .5,
  re_formula = NA
)+
  labs(fill="Growth\ntemperature",colour="Growth\ntemperature",
       x="Temperature",y="Metabolic rate")
```

## References

Kontopoulos, D..G., Sentis, A., Daufresne, M. et al. (2024) No universal mathematical model for thermal performance curves across traits and taxonomic groups. Nat Commun 15, 8855. <https://doi.org/10.1038/s41467-024-53046-2>

Padfield, D., Yvon-durocher, G., Buckling, A., Jennings, S. & Yvon-durocher, G. (2015). Rapid evolution of metabolic traits explains thermal adaptation in phytoplankton, Ecology Letters, 19, 133-142.

J. Arnoldi, A.L. Jackson, I. Peralta-Maraver, & N.L. Payne. (2025) A universal thermal performance curve arises in biology and ecology, Proc. Natl. Acad. Sci. U.S.A. 122 (43) e2513099122, <https://doi.org/10.1073/pnas.2513099122>.

```{r Session-Info}
sessionInfo()
```
